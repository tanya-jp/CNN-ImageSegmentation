# -*- coding: utf-8 -*-
"""HW3.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cdiUBfALlCVxgupRUcSSnfTO0pEKLco4
"""

# -*- coding: utf-8 -*-
"""DL4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zHW8i1oRz2-x1qMevcgZ_0DUEJgvK01r
"""

!wget http://www.vision.caltech.edu/Image_Datasets/Caltech256/256_ObjectCategories.tar

!tar -xf 256_ObjectCategories.tar

images_path = '256_ObjectCategories'
import glob
import cv2
import numpy as np
import matplotlib.pyplot as plt  

folders = glob.glob(images_path + '/*')
images = []
labels = []
for path in folders:
  label = int(path.split('.')[0].split('/')[-1])-1
#   print(label)
  images_path = glob.glob(path + '/*.jpg')
  images_path = images_path[::1]
  for image in images_path:
    img = cv2.imread(image)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.normalize(img.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)
    img = cv2.resize(img, (200,200))
#     img = img[:].flatten()
    images.append(img)
    labels.append(label)
# flatten
# import numpy as np
# print(np.shape(img))
# img_gray = gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# print(np.shape(img_gray))
# img_gray = img_gray[:].flatten()
# print(np.shape(img_gray))
#shuffle
import random
combined = list(zip(images, labels))
random.shuffle(combined)

images[:], labels[:] = zip(*combined)
X_train = images[:int(0.9*len(images))]
Y_train = labels[:int(0.9*len(images))]
X_test = images[int(0.9*len(images)):]
Y_test = labels[int(0.9*len(images)):]

path.split('.')[0].split('/')[-1]

from torch.utils.data import Dataset
import torch
class Caltech_Dataset(Dataset):    
    def __init__(self, images, labels):
        self.X = images
        self.Y = labels
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
#         import pdb;pdb.set_trace()
        image = torch.from_numpy(np.array(self.X[idx])).to(dtype=torch.float32)        
        return (image, self.Y[idx])

train_dataset=Caltech_Dataset(X_train,Y_train)
test_dataset=Caltech_Dataset(X_test,Y_test)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32)

# Network
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as dsets
from torch.autograd import Variable

batch_size = 32
n_iters = 3000
# num_epochs = n_iters / (len(train_dataset) / batch_size)
# num_epochs = int(num_epochs)
num_epochs = 20

class CNNModel(nn.Module):
  def __init__(self):
    super(CNNModel, self).__init__()
    
    # convolution 1
    self.cnn1 = nn.Conv2d(in_channels=1 ,out_channels=16 ,kernel_size=3 ,stride=1 ,padding=1)
    self.relu1 = nn.ReLU()
    
    # max pool 1 
    self.maxpool1 = nn.MaxPool2d(kernel_size=2)
    
    # convolution 2
    self.cnn2 = nn.Conv2d(in_channels=16 ,out_channels=32 ,kernel_size=3 ,stride=1 ,padding=1)
    self.relu2 = nn.ReLU()
    
    # max pool 2 
    self.maxpool2 = nn.MaxPool2d(kernel_size=2)
    
    # convolution 3
    self.cnn3 = nn.Conv2d(in_channels=32 ,out_channels=64 ,kernel_size=1 ,stride=1 ,padding=1)
    self.relu3 = nn.ReLU()
    
    # max pool 3 
    self.maxpool3 = nn.MaxPool2d(kernel_size=2)
    
    # convolution 4
    self.cnn4 = nn.Conv2d(in_channels=64 ,out_channels=128 ,kernel_size=1 ,stride=1 ,padding=1)
    self.relu4 = nn.ReLU()
    
    # max pool 4 
    self.maxpool4 = nn.MaxPool2d(kernel_size=2)
    
    # convolution 5
    self.cnn5 = nn.Conv2d(in_channels=128 ,out_channels=256 ,kernel_size=1 ,stride=1 ,padding=1)
    self.relu5 = nn.ReLU()
    
    # max pool 5 
    self.maxpool5 = nn.MaxPool2d(kernel_size=2)
    
    #fully connected 1 (readout)
    self.fc1 = nn.Linear(16384,output_dim).cuda()
    
  def forward(self, x):
        # convolution 1 
#         import pdb; pdb.set_trace()
        out = self.cnn1(x)
        out = self.relu1(out)
        # max pool 1 
        out = self.maxpool1(out)
        # convolution 2 
        out = self.cnn2(out)
        out = self.relu2(out)
        # max pool 2 
        out = self.maxpool2(out)
        # convolution 3 
        out = self.cnn3(out)
        out = self.relu3(out)
        # max pool 3 
        out = self.maxpool3(out)
        # convolution 4 
        out = self.cnn4(out)
        out = self.relu4(out)
        # max pool 4 
        out = self.maxpool4(out)
        # convolution 5
        out = self.cnn5(out)
        out = self.relu5(out)
        # max pool 5 
        out = self.maxpool5(out)
        
        out = out.view(out.size(0) ,-1)
        
        #linear function(readout)
        out = self.fc1(out)
        
        return out
'''
STEP 4: INSTANTIATE MODEL CLASS
'''
input_dim = 257
hidden_dim = 100
output_dim = 257

model = CNNModel()
#######################
#  USE GPU FOR MODEL  #
#######################
gpu = True
if gpu:
    model.cuda()

'''
STEP 5: INSTANTIATE LOSS CLASS
'''
criterion = nn.CrossEntropyLoss()


'''
STEP 6: INSTANTIATE OPTIMIZER CLASS
'''
learning_rate = 0.1

optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

'''
STEP 7: TRAIN THE MODEL
'''
accuracy_list=[]
accuracy_train_list=[]
loss_list=[]
loss_test_list=[]
x_list=[]
x_list2=[]
iter = 0
for epoch in range(num_epochs):
    correct_train = 0 
    total_train = 0
    for i, (images, labels) in enumerate(train_loader):
        
        #######################
        #  USE GPU FOR MODEL  #
        #######################
        if gpu:
            images = Variable(images.view(-1,1, 200,200)).cuda()
            labels = Variable(labels).cuda()
        else:
            images = Variable(images.view(-1,1, 200,200))
            labels = Variable(labels)
        
        # Clear gradients w.r.t. parameters
        optimizer.zero_grad()
        
        # Forward pass to get output/logits
        outputs = model(images)
        
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted.cpu() == labels.cpu()).sum()
        
        # Calculate Loss: softmax --> cross entropy loss
        loss_train = criterion(outputs, labels)
#         print(labels)
#         print(loss)
        # Getting gradients w.r.t. parameters
        loss_train.backward()
        
        # Updating parameters
        optimizer.step()
        
        iter += 1
        
        if iter % 500 == 0:
            # Calculate Accuracy         
            correct = 0
            total = 0
            avrg_loss = 0
            count = 1
            # Iterate through test dataset
            for images, labels in test_loader:
                #######################
                #  USE GPU FOR MODEL  #
                #######################
                if gpu:
                  images = Variable(images.view(-1,1, 200,200)).cuda()
                else:
                  images = Variable(images.view(-1,1, 200,200))
                
                # Forward pass only to get logits/output
                outputs = model(images)
                
                # Get predictions from the maximum value
                _, predicted = torch.max(outputs.data, 1)
                
                # Total number of labels
                total += labels.size(0)
                
                #######################
                #  USE GPU FOR MODEL  #
                #######################
                # Total correct predictions
                correct += (predicted.cpu() == labels.cpu()).sum()
                
                # Clear gradients w.r.t. parameters
#                 optimizer.zero_grad()
        
                # Calculate Loss: softmax --> cross entropy loss
                loss_test = criterion(outputs, labels.cuda())
      #         print(labels)
      #         print(loss)
                # Getting gradients w.r.t. parameters
                loss_test.backward()
                avrg_loss +=loss_test
                count +=1
            
            avrg_loss  = avrg_loss/count            
            loss_test_list.append(avrg_loss)
            accuracy_test = 100 * correct.numpy() / total
            x_list.append(iter)
            accuracy_list.append(accuracy_test)
            loss_list.append(loss_train)
#             loss_test_list.append(avrg_loss/count)
############
    accuracy_train = 100 * correct_train.numpy() / total_train
    accuracy_train_list.append(accuracy_train)
    x_list2.append(iter)
            
plt.figure()
ax1 = plt.subplot2grid((2,2), (0,0))
ax1.plot(x_list,accuracy_list)
plt.title('accuracy,test')
#               plt.xlabel('x [m]')
#               plt.ylabel('x\' []')

ax2 = plt.subplot2grid((2,2), (0,1))
ax2.plot(x_list,loss_test_list)
plt.title('loss,test')
#               plt.xlabel('x [m]')
#               plt.ylabel('x\' []')

ax3 = plt.subplot2grid((2,2), (1,0))
ax3.plot(x_list2,accuracy_train_list)
plt.title('accuracy,train')

ax4 = plt.subplot2grid((2,2), (1,1))
ax4.plot(x_list,loss_list)
plt.title('loss,train')


    
plt.show()
# x_list.clear()
# accuracy_list.clear()
# loss_list.clear()
#     accuracy_list=[accuracy_test]
#     loss_list=[loss_train]
#     loss_test_list=[loss_test]
#     x_list=[iter]

          
nn_filter = model.cnn1.weight.cpu()
fig = plt.figure()
for idx, filt  in enumerate(nn_filter):
    #print(filt[0, :, :])
    plt.subplot(8,8, idx + 1)
    normalized_filter = cv2.normalize(filt[ :, :].detach().numpy(),None,norm_type=cv2.NORM_MINMAX)
    plt.imshow(normalized_filter[0])
    plt.axis('off')
plt.suptitle('First Layer Filters')
plt.show()